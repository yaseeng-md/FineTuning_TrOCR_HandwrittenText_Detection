{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Gandluru Mohammed Yaseen  \n",
    "Reg.No : 12409548  \n",
    "M.Tech specialized in AI and ML  \n",
    "Lovely Professional University  \n",
    "Mobile: 8328377285  \n",
    "mail : gandlurumohammedyaseen@gmail.com  \n",
    "LinkedIn: [yaseeng-md](https://www.linkedin.com/in/yaseeng-md/)  \n",
    "GitHub: [yaseeng-md](http://www.github.com/yaseeng-md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Libraries and Import them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Librabries using pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:35:53.491902Z",
     "iopub.status.busy": "2025-05-16T06:35:53.491582Z",
     "iopub.status.idle": "2025-05-16T06:35:57.263205Z",
     "shell.execute_reply": "2025-05-16T06:35:57.262229Z",
     "shell.execute_reply.started": "2025-05-16T06:35:53.491884Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers evaluate datasets jiwer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "\n",
    "# Third-party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Kaggle & logging\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Hugging Face\n",
    "from evaluate import load\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, default_data_collator, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-16T06:35:46.745420Z",
     "iopub.status.busy": "2025-05-16T06:35:46.745158Z",
     "iopub.status.idle": "2025-05-16T06:35:53.490385Z",
     "shell.execute_reply": "2025-05-16T06:35:53.489792Z",
     "shell.execute_reply.started": "2025-05-16T06:35:46.745397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/iam-trocr/IAM/image/d04-037-00.jpg\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))\n",
    "        pass\n",
    "print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:36:02.458578Z",
     "iopub.status.busy": "2025-05-16T06:36:02.458312Z",
     "iopub.status.idle": "2025-05-16T06:36:02.514799Z",
     "shell.execute_reply": "2025-05-16T06:36:02.514241Z",
     "shell.execute_reply.started": "2025-05-16T06:36:02.458551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c04-110-00.jpg</td>\n",
       "      <td>Become a success with a disc and hey presto ! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c04-110-01.jpg</td>\n",
       "      <td>assuredness \" Bella Bella Marie \" ( Parlophone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c04-110-02.jpg</td>\n",
       "      <td>I don't think he will storm the charts with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c04-110-03.jpg</td>\n",
       "      <td>CHRIS CHARLES , 39 , who lives in Stockton-on-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c04-116-00.jpg</td>\n",
       "      <td>He is also a director of a couple of garages ....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file_name                                               text\n",
       "0  c04-110-00.jpg  Become a success with a disc and hey presto ! ...\n",
       "1  c04-110-01.jpg  assuredness \" Bella Bella Marie \" ( Parlophone...\n",
       "2  c04-110-02.jpg  I don't think he will storm the charts with th...\n",
       "3  c04-110-03.jpg  CHRIS CHARLES , 39 , who lives in Stockton-on-...\n",
       "4  c04-116-00.jpg  He is also a director of a couple of garages ...."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_fwf('/kaggle/input/iam-trocr/IAM/gt_test.txt', header=None)\n",
    "df.rename(columns={0: \"file_name\", 1: \"text\"}, inplace=True)\n",
    "del df[2]\n",
    "df['file_name'] = df['file_name'].apply(lambda x: x + 'g' if x.endswith('jp') else x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:36:02.516586Z",
     "iopub.status.busy": "2025-05-16T06:36:02.516353Z",
     "iopub.status.idle": "2025-05-16T06:36:03.093184Z",
     "shell.execute_reply": "2025-05-16T06:36:03.092642Z",
     "shell.execute_reply.started": "2025-05-16T06:36:02.516562Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Dataset Creation class using torch.Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:36:03.094317Z",
     "iopub.status.busy": "2025-05-16T06:36:03.093979Z",
     "iopub.status.idle": "2025-05-16T06:36:07.097274Z",
     "shell.execute_reply": "2025-05-16T06:36:07.096747Z",
     "shell.execute_reply.started": "2025-05-16T06:36:03.094297Z"
    }
   },
   "outputs": [],
   "source": [
    "class IAMDataset(Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for OCR fine-tuning using the IAM Handwriting dataset (or similar).\n",
    "    \n",
    "    This dataset class loads images and their corresponding text labels, processes them using\n",
    "    a TrOCRProcessor (from Hugging Face), and returns the required inputs for training a \n",
    "    VisionEncoderDecoderModel such as TrOCR.\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): Path to the directory containing image files.\n",
    "        df (pd.DataFrame): DataFrame with two columns: \n",
    "                           'file_name' (relative image path) and 'text' (ground-truth transcription).\n",
    "        processor (TrOCRProcessor): Processor for both image and text (handles feature extraction & tokenization).\n",
    "        max_target_length (int): Maximum length for tokenized text labels. Default is 128.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = self.df['text'][idx]\n",
    "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                          padding=\"max_length\", \n",
    "                                          max_length=self.max_target_length).input_ids\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Instance and Preprocess the dataset according to TrOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:36:07.098342Z",
     "iopub.status.busy": "2025-05-16T06:36:07.098022Z",
     "iopub.status.idle": "2025-05-16T06:36:28.862118Z",
     "shell.execute_reply": "2025-05-16T06:36:28.861304Z",
     "shell.execute_reply.started": "2025-05-16T06:36:07.098324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-16 06:36:13.733437: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747377373.926162      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747377373.983235      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6a3748e8a4480692cf524c022e5b9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/224 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3fd895c8794e22bdad6235476c247d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39b5f04795e4c4f8aa6e8b96d1818d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a81df6186bb4685803ca2fe1dd6d65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5171c3893c7e462098047398973ad5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-large-handwritten\")\n",
    "train_dataset = IAMDataset(root_dir='/kaggle/input/iam-trocr/IAM/image/',\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "eval_dataset = IAMDataset(root_dir='/kaggle/input/iam-trocr/IAM/image/',\n",
    "                           df=test_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:36:28.863548Z",
     "iopub.status.busy": "2025-05-16T06:36:28.862973Z",
     "iopub.status.idle": "2025-05-16T06:36:44.074209Z",
     "shell.execute_reply": "2025-05-16T06:36:44.072581Z",
     "shell.execute_reply.started": "2025-05-16T06:36:28.863506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e51ee145654a828de82a0218433a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2ea4f5b88d46f1b3c1e54e12da2a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.23G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192568f2d1b64a6ebb02035060e96135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.23G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"patch_size\": 16,\n",
      "  \"pooler_act\": \"tanh\",\n",
      "  \"pooler_output_size\": 1024,\n",
      "  \"qkv_bias\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 1024,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b0e37be2a2480c976105b7c7eecfda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-large-handwritten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set model Parameters and Cofigarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:36:44.075454Z",
     "iopub.status.busy": "2025-05-16T06:36:44.075270Z",
     "iopub.status.idle": "2025-05-16T06:36:49.732830Z",
     "shell.execute_reply": "2025-05-16T06:36:49.732026Z",
     "shell.execute_reply.started": "2025-05-16T06:36:44.075440Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    predict_with_generate=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,                  \n",
    "    num_train_epochs=10,                 \n",
    "    fp16=True,\n",
    "    logging_steps=2,\n",
    "    save_steps=1000,\n",
    "    eval_steps=200,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the required Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:37:03.373576Z",
     "iopub.status.busy": "2025-05-16T06:37:03.373329Z",
     "iopub.status.idle": "2025-05-16T06:37:04.522375Z",
     "shell.execute_reply": "2025-05-16T06:37:04.521661Z",
     "shell.execute_reply.started": "2025-05-16T06:37:03.373551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d570088653949e08185250c75424565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dd2a3f54614759802eca4cfeb656c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cer_metric = load(\"cer\")\n",
    "wer_metric = load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:37:04.523268Z",
     "iopub.status.busy": "2025-05-16T06:37:04.523071Z",
     "iopub.status.idle": "2025-05-16T06:37:04.527752Z",
     "shell.execute_reply": "2025-05-16T06:37:04.527132Z",
     "shell.execute_reply.started": "2025-05-16T06:37:04.523252Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer, \"wer\": wer}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login into wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:37:04.529037Z",
     "iopub.status.busy": "2025-05-16T06:37:04.528791Z",
     "iopub.status.idle": "2025-05-16T06:37:10.960127Z",
     "shell.execute_reply": "2025-05-16T06:37:10.959582Z",
     "shell.execute_reply.started": "2025-05-16T06:37:04.529022Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgandlurumohammedyaseen\u001b[0m (\u001b[33mgandlurumohammedyaseen-lovely-professional-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_secrets = UserSecretsClient()\n",
    "wandb_api_key = user_secrets.get_secret(\"wandb_api_key\")\n",
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile the model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T06:37:10.963372Z",
     "iopub.status.busy": "2025-05-16T06:37:10.962846Z",
     "iopub.status.idle": "2025-05-16T09:27:07.274405Z",
     "shell.execute_reply": "2025-05-16T09:27:07.273860Z",
     "shell.execute_reply.started": "2025-05-16T06:37:10.963353Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/trocr/processing_trocr.py:152: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_35/2936316434.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250516_063713-0aay9ct5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gandlurumohammedyaseen-lovely-professional-university/huggingface/runs/0aay9ct5' target=\"_blank\">./</a></strong> to <a href='https://wandb.ai/gandlurumohammedyaseen-lovely-professional-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gandlurumohammedyaseen-lovely-professional-university/huggingface' target=\"_blank\">https://wandb.ai/gandlurumohammedyaseen-lovely-professional-university/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gandlurumohammedyaseen-lovely-professional-university/huggingface/runs/0aay9ct5' target=\"_blank\">https://wandb.ai/gandlurumohammedyaseen-lovely-professional-university/huggingface/runs/0aay9ct5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2920' max='2920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2920/2920 2:49:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Cer</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.720700</td>\n",
       "      <td>3.284099</td>\n",
       "      <td>0.502517</td>\n",
       "      <td>0.657556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.166900</td>\n",
       "      <td>2.197404</td>\n",
       "      <td>0.460570</td>\n",
       "      <td>0.625146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.258800</td>\n",
       "      <td>1.938377</td>\n",
       "      <td>0.498482</td>\n",
       "      <td>0.654432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.635800</td>\n",
       "      <td>1.763478</td>\n",
       "      <td>0.501119</td>\n",
       "      <td>0.658141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.455100</td>\n",
       "      <td>1.726363</td>\n",
       "      <td>0.477349</td>\n",
       "      <td>0.630223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.624600</td>\n",
       "      <td>1.672589</td>\n",
       "      <td>0.466603</td>\n",
       "      <td>0.614799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>1.603672</td>\n",
       "      <td>0.493129</td>\n",
       "      <td>0.640180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>1.479471</td>\n",
       "      <td>0.493568</td>\n",
       "      <td>0.636861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>1.380923</td>\n",
       "      <td>0.485099</td>\n",
       "      <td>0.637251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>1.441660</td>\n",
       "      <td>0.473594</td>\n",
       "      <td>0.611480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>1.372854</td>\n",
       "      <td>0.466083</td>\n",
       "      <td>0.610894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>1.317068</td>\n",
       "      <td>0.466043</td>\n",
       "      <td>0.604842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>1.252985</td>\n",
       "      <td>0.463087</td>\n",
       "      <td>0.591566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>1.228167</td>\n",
       "      <td>0.459012</td>\n",
       "      <td>0.586294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 64, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2920, training_loss=0.879230626709823, metrics={'train_runtime': 10193.9153, 'train_samples_per_second': 2.288, 'train_steps_per_second': 0.286, 'total_flos': 3.1333599936679772e+19, 'train_loss': 0.879230626709823, 'epoch': 10.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T09:45:27.952746Z",
     "iopub.status.busy": "2025-05-16T09:45:27.952162Z",
     "iopub.status.idle": "2025-05-16T09:45:27.970876Z",
     "shell.execute_reply": "2025-05-16T09:45:27.970094Z",
     "shell.execute_reply.started": "2025-05-16T09:45:27.952726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionEncoderDecoderModel(\n",
       "  (encoder): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (pooler): ViTPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (decoder): TrOCRForCausalLM(\n",
       "    (model): TrOCRDecoderWrapper(\n",
       "      (decoder): TrOCRDecoder(\n",
       "        (embed_tokens): TrOCRScaledWordEmbedding(50265, 1024, padding_idx=1)\n",
       "        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 1024)\n",
       "        (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (layers): ModuleList(\n",
       "          (0-11): 12 x TrOCRDecoderLayer(\n",
       "            (self_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (activation_fn): GELUActivation()\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): TrOCRAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_projection): Linear(in_features=1024, out_features=50265, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T09:45:38.728143Z",
     "iopub.status.busy": "2025-05-16T09:45:38.727624Z",
     "iopub.status.idle": "2025-05-16T09:45:38.751900Z",
     "shell.execute_reply": "2025-05-16T09:45:38.750955Z",
     "shell.execute_reply.started": "2025-05-16T09:45:38.728123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the image\n",
    "image_path = \"/kaggle/input/iam-trocr/IAM/image/d04-037-00.jpg\"\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Resize and normalize as expected by TrOCR\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "pixel_values = pixel_values.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-16T09:46:49.309052Z",
     "iopub.status.busy": "2025-05-16T09:46:49.308494Z",
     "iopub.status.idle": "2025-05-16T09:46:49.919809Z",
     "shell.execute_reply": "2025-05-16T09:46:49.919010Z",
     "shell.execute_reply.started": "2025-05-16T09:46:49.309030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Text: Then whole earth be will Hisar \" it it\n"
     ]
    }
   ],
   "source": [
    "# Generate prediction\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Input Image\")\n",
    "plt.show()\n",
    "\n",
    "# Decode prediction\n",
    "predicted_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(\"Predicted Text:\", predicted_text)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4125061,
     "sourceId": 7145944,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
